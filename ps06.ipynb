{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO371 Problem Set 6: Naive Bayes\n",
    "## 1 Load data\n",
    "Load data and split it into working and testing chunks. But before you begin: ensure you can save a\n",
    "dataframe in a format you can load back in afterwards. pd.to_csv is a good bet, but it has a lot of\n",
    "options which may screw up the way you read data. Ensure you can store data in a way that you can\n",
    "read it back in correctly, including that missings remain missings.\n",
    "1. create a tiny toy data frame that includes some numbers, strings, and missings. Save it and ensure\n",
    "you can reload it in the correct form.\n",
    "Now you are good to go:\n",
    "2. load the data (available on canvas: files/data/rotten-tomatoes.csv). DO NOT LOOK AT IT!\n",
    "3. split the dataset into working-testing parts (80/20 or so). Note that sklearn's train_test_split\n",
    "can easily handle dataframes. Just for your confirmation, ensure that the size of the working and\n",
    "testing data look reasonable.\n",
    "4. now save the test data and delete it from memory. Use python's del statement, or R-s rm function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maplotlib version:     2.2.3\n"
     ]
    }
   ],
   "source": [
    "#load libraries \n",
    "import matplotlib \n",
    "print(\"Maplotlib version:    %6.6s\" % matplotlib.__version__)\n",
    "%matplotlib inline\n",
    "# needed for inline plots in notebooks\n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a tiny toy dataframe?\n",
    "tiny = pd.DataFrame(np.random.randn(5, 3), index=['a', 'c', 'e', 'f', 'h'], \n",
    "                  columns=['one', 'two', 'three'])\n",
    "tiny['four'] = 'bar'\n",
    "tiny['five'] = tiny['one'] > 0\n",
    "tiny = tiny.reindex(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])\n",
    "\n",
    "#save file\n",
    "tiny.to_csv('tiny.csv', sep='\\t', encoding='utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one</th>\n",
       "      <th>two</th>\n",
       "      <th>three</th>\n",
       "      <th>four</th>\n",
       "      <th>five</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.302547</td>\n",
       "      <td>0.153268</td>\n",
       "      <td>-1.138920</td>\n",
       "      <td>bar</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.050233</td>\n",
       "      <td>-2.062735</td>\n",
       "      <td>-0.888332</td>\n",
       "      <td>bar</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.299053</td>\n",
       "      <td>-0.400327</td>\n",
       "      <td>0.132046</td>\n",
       "      <td>bar</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.421729</td>\n",
       "      <td>0.729466</td>\n",
       "      <td>0.364479</td>\n",
       "      <td>bar</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.905065</td>\n",
       "      <td>-1.953972</td>\n",
       "      <td>-0.209700</td>\n",
       "      <td>bar</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        one       two     three four   five\n",
       "0  0.302547  0.153268 -1.138920  bar   True\n",
       "1       NaN       NaN       NaN  NaN    NaN\n",
       "2 -1.050233 -2.062735 -0.888332  bar  False\n",
       "3       NaN       NaN       NaN  NaN    NaN\n",
       "4  0.299053 -0.400327  0.132046  bar   True\n",
       "5  0.421729  0.729466  0.364479  bar   True\n",
       "6       NaN       NaN       NaN  NaN    NaN\n",
       "7 -0.905065 -1.953972 -0.209700  bar  False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload_tiny = pd.read_csv('tiny.csv', sep = '\\t')\n",
    "reload_tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "critic         705\n",
       "fresh            0\n",
       "imdb             0\n",
       "link             0\n",
       "publication      0\n",
       "quote            0\n",
       "review_date      0\n",
       "rtid             0\n",
       "title            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tomatoes = pd.read_csv(\"rotten-tomatoes.csv.gz\")\n",
    "tomatoes.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'test_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-6bb2d1730f68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     tomatoes, test_size = 0.2, random_state = 11)\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test_data.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   1743\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 1745\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1747\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    154\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[0;32m    155\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m                                      compression=self.compression)\n\u001b[0m\u001b[0;32m    157\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;31m# Python 3 and encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[1;31m# Python 3 and no explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'test_data.csv'"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "tomatoes = pd.read_csv(\"rotten-tomatoes.csv.gz\")\n",
    "\n",
    "tomatoes = tomatoes.dropna(subset=['fresh'])\n",
    "tomatoes = tomatoes.loc[tomatoes.fresh != 'none']\n",
    "\n",
    "train,test = train_test_split(\n",
    "    tomatoes, test_size = 0.2, random_state = 11)\n",
    "\n",
    "test.to_csv('test_data.csv', sep='\\t', encoding='utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fresh', 'rotten'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tomatoes.fresh.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Explore and clean the data\n",
    "Now when the test data is put aside, we can breath out and take a closer look how does the work data\n",
    "look like.\n",
    "1. Take a look at a few lines of data (you may use pd.sample for this).\n",
    "2. print out all variable names.\n",
    "3. create a summary table (maybe more like a bullet list) where you print out the most important\n",
    "summary statistics for the most interesting variables. The most interesting facts you should present\n",
    "should include: a) number of missings for fresh and quote; b) all different values for fresh/rotten\n",
    "evaluations; c) counts or percentages of these values; d) number of zero-length or only whitespace\n",
    "quote-s; e) minimum-maximum-average length of quotes (either in words, or in characters). (Can\n",
    "you do this as an one-liner?); f) how many reviews are in data multiple times. Feel free to add more\n",
    "figures you consider relevant.\n",
    "4. Now when you have an overview what you have in data, clean it by removing all the inconsistencies\n",
    "the table reveals. We have to ensure that the central variables: quote and fresh are not missing, and\n",
    "quote is not an empty string (or just contain spaces and such).\n",
    "I strongly recommend to do it as a standalone function because at the end you have to perform\n",
    "exactly the same cleaning operations with your test data too.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  critic   fresh    imdb  \\\n",
      "4188  Jonathan Rosenbaum  rotten  116908   \n",
      "3778          A.O. Scott  rotten  430770   \n",
      "4927      Desson Thomson   fresh   93191   \n",
      "4166          Hal Hinson  rotten   95016   \n",
      "3282      Stephen Holden   fresh  134618   \n",
      "\n",
      "                                                   link      publication  \\\n",
      "4188  http://www.chicagoreader.com/chicago/the-long-...   Chicago Reader   \n",
      "3778  http://movies.nytimes.com/2008/09/12/movies/12...   New York Times   \n",
      "4927  http://www.washingtonpost.com/wp-srv/style/lon...  Washington Post   \n",
      "4166  http://www.washingtonpost.com/wp-srv/style/lon...  Washington Post   \n",
      "3282  http://movies.nytimes.com/movie/review?res=9A0...   New York Times   \n",
      "\n",
      "                                                  quote          review_date  \\\n",
      "4188  Frankly, if I had to see either Harlin-Davis m...  2011-10-25 00:00:00   \n",
      "3778  It hurts especially to watch Ms. Bening and Ca...  2008-09-12 00:00:00   \n",
      "4927  a soaring vision that appeals to the senses an...  2000-01-01 00:00:00   \n",
      "4166  It gets your heart pounding, then makes you ha...  2000-01-01 00:00:00   \n",
      "3282  Conveys some of the thrill and ferocity of ice...  2000-01-01 00:00:00   \n",
      "\n",
      "           rtid                    title  \n",
      "4188      13322  The Long Kiss Goodnight  \n",
      "3778  371357838                The Women  \n",
      "4927      10221          Wings of Desire  \n",
      "4166      16351                 Die Hard  \n",
      "3282      12982          Mystery, Alaska  \n",
      "['critic', 'fresh', 'imdb', 'link', 'publication', 'quote', 'review_date', 'rtid', 'title']\n"
     ]
    }
   ],
   "source": [
    "print(train.sample(5))\n",
    "print(list(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "critic         558\n",
      "fresh            0\n",
      "imdb             0\n",
      "link             0\n",
      "publication      0\n",
      "quote            0\n",
      "review_date      0\n",
      "rtid             0\n",
      "title            0\n",
      "dtype: int64\n",
      "['rotten' 'fresh']\n",
      "(fresh = fresh): 6709\n",
      "(fresh = rotten): 4026\n",
      "(fresh = none): 0\n",
      "quotes with whitespace: 0\n",
      "number of rows with dumplicate reviews: 379\n"
     ]
    }
   ],
   "source": [
    "#summary table for tomatoe train\n",
    "print(train.isnull().sum())\n",
    "print(train['fresh'].unique())\n",
    "\n",
    "print('(fresh = fresh): ' + str((train.fresh == 'fresh').sum()))\n",
    "print('(fresh = rotten): ' + str((train.fresh == 'rotten').sum()))\n",
    "print('(fresh = none): ' + str((train.fresh == 'none').sum()))\n",
    "\n",
    "\n",
    "#quotes\n",
    "quotes = train.quote.unique()\n",
    "emptyquotes = 0\n",
    "for quote in quotes: \n",
    "    if quote.isspace(): \n",
    "        emptyquotes += 1\n",
    "print(\"quotes with whitespace: \" + str(emptyquotes))\n",
    "\n",
    "print('number of rows with dumplicate reviews: ' + str(train.duplicated().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 NaÃ¯ve Bayes\n",
    "Now where you are familiar with the data, it's time to get serious and implement the Naive Bayes classifier\n",
    "from scratch. But first things first.\n",
    "1. Ensure you are familiar with Naive Bayes. Consult the readings, available on canvas. Schutt &\n",
    "O'Neill is an easy and accessible (and long) introduction, Whitten & Frank is a lot shorter but still\n",
    "accessible introduction.\n",
    "2. Convert your data (quotes) into bag-of-words. Your code should look something along the lines as\n",
    "in PS4:\n",
    "\n",
    "However, now we don't want BOW that contains counts of words in quotes, but just 1/0 (or true/-\n",
    "false) for the presence/non-presence of the words. Convert the count-based BOW into such a presence\n",
    "BOW. Hint: think in terms of vectorized (universal) functions.\n",
    "3. Split your work data and target (i.e. the variable fresh) into training and validation chunks (80/20\n",
    "or so). Later we also do cross-validation, but for now, a simple training/validation will do.\n",
    "Good. Now you are ready with the preparatory work and it's time to dive into the real thing. Let's\n",
    "implement Naive Bayes. Use only training data in the fitting below.\n",
    "*remember there are more directions*\n",
    "\n",
    "\n",
    "\n",
    "7. Print the resulting confusion matrix and accuracy (feel free to use existing libraries).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to bag of words\n",
    "vectorizer = CountVectorizer()\n",
    "# define vecotrizer\n",
    "X = vectorizer.fit_transform(train.quote.values)\n",
    "# vectorize your data. Note: this creates a sparce matrix,\n",
    "# use .toarray() if you want a dense matrix.\n",
    "words = vectorizer.get_feature_names()\n",
    "# in case you want to see what are the actual words\n",
    "#replace counts above 1 with binary value 1\n",
    "X[X > 1] = 1\n",
    "#split data and target into training and validation parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, train['fresh'], test_size = 0.2, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#priori probability of being fresh or rotten\n",
    "f = len(y_train[y_train == 'fresh'])/len(y_train)\n",
    "r = len(y_train[y_train == 'rotten'])/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile X_train into a dataframe\n",
    "X_train = X_train.toarray()\n",
    "X_train_df = pd.DataFrame(data = X_train, columns = words)\n",
    "X_train_df['_val'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the total instances each words shows up in rotten quotes\n",
    "rottentotal = X_train_df.loc[X_train_df['_val'] == 'rotten']\n",
    "rottentotal = rottentotal.sum(axis = 0)\n",
    "rottentotal = rottentotal[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating total instances each word shows up in fresh quotes\n",
    "freshtotal = X_train_df.loc[X_train_df['_val'] == 'fresh']\n",
    "freshtotal = freshtotal.sum(axis = 0)\n",
    "freshtotal = freshtotal[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rottenprob = rottentotal/sum(rottentotal)\n",
    "freshprob = freshtotal/sum(freshtotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame()\n",
    "table['fresh_counts'] = freshtotal\n",
    "table['rotten_counts'] = rottentotal\n",
    "table['fresh_prob'] = freshprob\n",
    "table['rotten_prob'] = rottenprob\n",
    "table = table.reset_index()\n",
    "table.columns = ['word', 'f_counts', 'r_counts', 'f_prob', 'r_prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function finds fresh and rotten probabilities associated with one BOW quote\n",
    "#stores both fresh probabilities and rotten probabilities into two lists\n",
    "def findProb(quote, table):\n",
    "    fresh_probability = []\n",
    "    rotten_probability = []\n",
    "    for i in range(len(quote)): \n",
    "        if quote[i] == 1:\n",
    "                fresh_probability.append(table.f_prob[i])\n",
    "                rotten_probability.append(table.r_prob[i])\n",
    "    return fresh_probability, rotten_probability    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {'fp': [], 'rp': []}\n",
    "for row in X_test:\n",
    "    fp, rp = findProb(row, table)\n",
    "    freshp = 0\n",
    "    rottenp = 0\n",
    "    freshp = np.prod(fp) * f\n",
    "    rottenp = np.prod(rp) * r\n",
    "    predictions['fp'].append(freshp)\n",
    "    predictions['rp'].append(rottenp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_df = pd.DataFrame(data = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6396     rotten\n",
       "5717      fresh\n",
       "6747     rotten\n",
       "12911     fresh\n",
       "11323     fresh\n",
       "Name: fresh, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_df['indices'] = y_test.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_df['pred'] = probabilities_df['fp'] > probabilities_df['rp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fp</th>\n",
       "      <th>rp</th>\n",
       "      <th>indices</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>357</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>2.921434e-38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>11332</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7343</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>12928</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>13389</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4314</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>7.623648e-78</td>\n",
       "      <td>1.226950e-77</td>\n",
       "      <td>3698</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2071</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>5.335669e-79</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3807</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>1.069225e-87</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8247</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                fp            rp  indices    pred\n",
       "1813  0.000000e+00  0.000000e+00      357  rotten\n",
       "1710  2.921434e-38  0.000000e+00    11332   fresh\n",
       "268   0.000000e+00  0.000000e+00     7343  rotten\n",
       "326   0.000000e+00  0.000000e+00    12928  rotten\n",
       "559   0.000000e+00  0.000000e+00    13389  rotten\n",
       "1910  0.000000e+00  0.000000e+00     4314  rotten\n",
       "1979  7.623648e-78  1.226950e-77     3698  rotten\n",
       "396   0.000000e+00  0.000000e+00     2071  rotten\n",
       "67    5.335669e-79  0.000000e+00     3807   fresh\n",
       "1475  1.069225e-87  0.000000e+00     8247   fresh"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities_df['pred'] = probabilities_df['pred'].replace([True, False], ['fresh', 'rotten'])\n",
    "probabilities_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4648346530041919"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, probabilities_df.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[372, 960],\n",
       "       [189, 626]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating confusion matrix\n",
    "confusion_matrix(y_test, probabilities_df.pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Interpretation\n",
    "Now it is time to look at your fitted model a little bit closer. NB model probabilities are rather easy to\n",
    "understand and interpret. The task here is to find the best words to predict a fresh, and a rotten review.\n",
    "And we only want to look at words that are reasonably frequent, say more frequent than 30 times in the\n",
    "data.\n",
    "\n",
    "2. Find 10 best words to predict F and 10 best words to predict R. Hint: imagine we have a review that\n",
    "contains just a single word. Which word will give the highest weight to the probability the review is\n",
    "fresh? Which one to the likelihood it is rotten?\n",
    "Comment your results.\n",
    "3. Print out a few missclassified quotes. Can you understand why these are misclassified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stop = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \n",
    "                  \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \n",
    "                  \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\",\n",
    "                  \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\",\n",
    "                  \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\",\n",
    "                  \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \n",
    "                  \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\",\n",
    "                  \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \n",
    "                  \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\",\n",
    "                  \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\",\n",
    "                  \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\",\n",
    "                  \"will\", \"just\", \"don\", \"should\", \"now\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(table)):\n",
    "    if table.word[i] in nltk_stop:\n",
    "        table = table.drop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort table\n",
    "table_f = table.sort_values(by = 'f_prob', ascending = False).head(20)\n",
    "\n",
    "table_r = table.sort_values(by = 'r_prob', ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>f_counts</th>\n",
       "      <th>r_counts</th>\n",
       "      <th>f_prob</th>\n",
       "      <th>r_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6327</th>\n",
       "      <td>film</td>\n",
       "      <td>549</td>\n",
       "      <td>318</td>\n",
       "      <td>0.00845188</td>\n",
       "      <td>0.00916664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10994</th>\n",
       "      <td>movie</td>\n",
       "      <td>465</td>\n",
       "      <td>282</td>\n",
       "      <td>0.00715869</td>\n",
       "      <td>0.00812891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11621</th>\n",
       "      <td>one</td>\n",
       "      <td>287</td>\n",
       "      <td>170</td>\n",
       "      <td>0.00441838</td>\n",
       "      <td>0.00490041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9768</th>\n",
       "      <td>like</td>\n",
       "      <td>184</td>\n",
       "      <td>106</td>\n",
       "      <td>0.00283269</td>\n",
       "      <td>0.00305555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7255</th>\n",
       "      <td>good</td>\n",
       "      <td>160</td>\n",
       "      <td>92</td>\n",
       "      <td>0.00246321</td>\n",
       "      <td>0.00265198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16143</th>\n",
       "      <td>story</td>\n",
       "      <td>156</td>\n",
       "      <td>84</td>\n",
       "      <td>0.00240163</td>\n",
       "      <td>0.00242138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5750</th>\n",
       "      <td>even</td>\n",
       "      <td>143</td>\n",
       "      <td>54</td>\n",
       "      <td>0.00220149</td>\n",
       "      <td>0.0015566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17141</th>\n",
       "      <td>time</td>\n",
       "      <td>133</td>\n",
       "      <td>77</td>\n",
       "      <td>0.00204754</td>\n",
       "      <td>0.0022196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3286</th>\n",
       "      <td>comedy</td>\n",
       "      <td>130</td>\n",
       "      <td>79</td>\n",
       "      <td>0.00200135</td>\n",
       "      <td>0.00227725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11014</th>\n",
       "      <td>much</td>\n",
       "      <td>128</td>\n",
       "      <td>83</td>\n",
       "      <td>0.00197056</td>\n",
       "      <td>0.00239255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4704</th>\n",
       "      <td>director</td>\n",
       "      <td>126</td>\n",
       "      <td>66</td>\n",
       "      <td>0.00193977</td>\n",
       "      <td>0.00190251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>best</td>\n",
       "      <td>120</td>\n",
       "      <td>63</td>\n",
       "      <td>0.0018474</td>\n",
       "      <td>0.00181603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>characters</td>\n",
       "      <td>111</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00170885</td>\n",
       "      <td>0.0014413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18578</th>\n",
       "      <td>well</td>\n",
       "      <td>111</td>\n",
       "      <td>49</td>\n",
       "      <td>0.00170885</td>\n",
       "      <td>0.00141247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12367</th>\n",
       "      <td>picture</td>\n",
       "      <td>111</td>\n",
       "      <td>52</td>\n",
       "      <td>0.00170885</td>\n",
       "      <td>0.00149895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>action</td>\n",
       "      <td>102</td>\n",
       "      <td>51</td>\n",
       "      <td>0.00157029</td>\n",
       "      <td>0.00147012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6389</th>\n",
       "      <td>first</td>\n",
       "      <td>101</td>\n",
       "      <td>51</td>\n",
       "      <td>0.0015549</td>\n",
       "      <td>0.00147012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10409</th>\n",
       "      <td>may</td>\n",
       "      <td>97</td>\n",
       "      <td>53</td>\n",
       "      <td>0.00149332</td>\n",
       "      <td>0.00152777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10107</th>\n",
       "      <td>made</td>\n",
       "      <td>93</td>\n",
       "      <td>52</td>\n",
       "      <td>0.00143174</td>\n",
       "      <td>0.00149895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6869</th>\n",
       "      <td>funny</td>\n",
       "      <td>92</td>\n",
       "      <td>54</td>\n",
       "      <td>0.00141634</td>\n",
       "      <td>0.0015566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word f_counts r_counts      f_prob      r_prob\n",
       "6327         film      549      318  0.00845188  0.00916664\n",
       "10994       movie      465      282  0.00715869  0.00812891\n",
       "11621         one      287      170  0.00441838  0.00490041\n",
       "9768         like      184      106  0.00283269  0.00305555\n",
       "7255         good      160       92  0.00246321  0.00265198\n",
       "16143       story      156       84  0.00240163  0.00242138\n",
       "5750         even      143       54  0.00220149   0.0015566\n",
       "17141        time      133       77  0.00204754   0.0022196\n",
       "3286       comedy      130       79  0.00200135  0.00227725\n",
       "11014        much      128       83  0.00197056  0.00239255\n",
       "4704     director      126       66  0.00193977  0.00190251\n",
       "1703         best      120       63   0.0018474  0.00181603\n",
       "2772   characters      111       50  0.00170885   0.0014413\n",
       "18578        well      111       49  0.00170885  0.00141247\n",
       "12367     picture      111       52  0.00170885  0.00149895\n",
       "356        action      102       51  0.00157029  0.00147012\n",
       "6389        first      101       51   0.0015549  0.00147012\n",
       "10409         may       97       53  0.00149332  0.00152777\n",
       "10107        made       93       52  0.00143174  0.00149895\n",
       "6869        funny       92       54  0.00141634   0.0015566"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>f_counts</th>\n",
       "      <th>r_counts</th>\n",
       "      <th>f_prob</th>\n",
       "      <th>r_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6327</th>\n",
       "      <td>film</td>\n",
       "      <td>549</td>\n",
       "      <td>318</td>\n",
       "      <td>0.00845188</td>\n",
       "      <td>0.00916664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10994</th>\n",
       "      <td>movie</td>\n",
       "      <td>465</td>\n",
       "      <td>282</td>\n",
       "      <td>0.00715869</td>\n",
       "      <td>0.00812891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11621</th>\n",
       "      <td>one</td>\n",
       "      <td>287</td>\n",
       "      <td>170</td>\n",
       "      <td>0.00441838</td>\n",
       "      <td>0.00490041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9768</th>\n",
       "      <td>like</td>\n",
       "      <td>184</td>\n",
       "      <td>106</td>\n",
       "      <td>0.00283269</td>\n",
       "      <td>0.00305555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7255</th>\n",
       "      <td>good</td>\n",
       "      <td>160</td>\n",
       "      <td>92</td>\n",
       "      <td>0.00246321</td>\n",
       "      <td>0.00265198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16143</th>\n",
       "      <td>story</td>\n",
       "      <td>156</td>\n",
       "      <td>84</td>\n",
       "      <td>0.00240163</td>\n",
       "      <td>0.00242138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11014</th>\n",
       "      <td>much</td>\n",
       "      <td>128</td>\n",
       "      <td>83</td>\n",
       "      <td>0.00197056</td>\n",
       "      <td>0.00239255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3286</th>\n",
       "      <td>comedy</td>\n",
       "      <td>130</td>\n",
       "      <td>79</td>\n",
       "      <td>0.00200135</td>\n",
       "      <td>0.00227725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17141</th>\n",
       "      <td>time</td>\n",
       "      <td>133</td>\n",
       "      <td>77</td>\n",
       "      <td>0.00204754</td>\n",
       "      <td>0.0022196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4704</th>\n",
       "      <td>director</td>\n",
       "      <td>126</td>\n",
       "      <td>66</td>\n",
       "      <td>0.00193977</td>\n",
       "      <td>0.00190251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>best</td>\n",
       "      <td>120</td>\n",
       "      <td>63</td>\n",
       "      <td>0.0018474</td>\n",
       "      <td>0.00181603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5750</th>\n",
       "      <td>even</td>\n",
       "      <td>143</td>\n",
       "      <td>54</td>\n",
       "      <td>0.00220149</td>\n",
       "      <td>0.0015566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9845</th>\n",
       "      <td>little</td>\n",
       "      <td>91</td>\n",
       "      <td>54</td>\n",
       "      <td>0.00140095</td>\n",
       "      <td>0.0015566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6869</th>\n",
       "      <td>funny</td>\n",
       "      <td>92</td>\n",
       "      <td>54</td>\n",
       "      <td>0.00141634</td>\n",
       "      <td>0.0015566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10409</th>\n",
       "      <td>may</td>\n",
       "      <td>97</td>\n",
       "      <td>53</td>\n",
       "      <td>0.00149332</td>\n",
       "      <td>0.00152777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15614</th>\n",
       "      <td>something</td>\n",
       "      <td>61</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000939097</td>\n",
       "      <td>0.00152777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10107</th>\n",
       "      <td>made</td>\n",
       "      <td>93</td>\n",
       "      <td>52</td>\n",
       "      <td>0.00143174</td>\n",
       "      <td>0.00149895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12367</th>\n",
       "      <td>picture</td>\n",
       "      <td>111</td>\n",
       "      <td>52</td>\n",
       "      <td>0.00170885</td>\n",
       "      <td>0.00149895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11003</th>\n",
       "      <td>movies</td>\n",
       "      <td>91</td>\n",
       "      <td>51</td>\n",
       "      <td>0.00140095</td>\n",
       "      <td>0.00147012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6389</th>\n",
       "      <td>first</td>\n",
       "      <td>101</td>\n",
       "      <td>51</td>\n",
       "      <td>0.0015549</td>\n",
       "      <td>0.00147012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word f_counts r_counts       f_prob      r_prob\n",
       "6327        film      549      318   0.00845188  0.00916664\n",
       "10994      movie      465      282   0.00715869  0.00812891\n",
       "11621        one      287      170   0.00441838  0.00490041\n",
       "9768        like      184      106   0.00283269  0.00305555\n",
       "7255        good      160       92   0.00246321  0.00265198\n",
       "16143      story      156       84   0.00240163  0.00242138\n",
       "11014       much      128       83   0.00197056  0.00239255\n",
       "3286      comedy      130       79   0.00200135  0.00227725\n",
       "17141       time      133       77   0.00204754   0.0022196\n",
       "4704    director      126       66   0.00193977  0.00190251\n",
       "1703        best      120       63    0.0018474  0.00181603\n",
       "5750        even      143       54   0.00220149   0.0015566\n",
       "9845      little       91       54   0.00140095   0.0015566\n",
       "6869       funny       92       54   0.00141634   0.0015566\n",
       "10409        may       97       53   0.00149332  0.00152777\n",
       "15614  something       61       53  0.000939097  0.00152777\n",
       "10107       made       93       52   0.00143174  0.00149895\n",
       "12367    picture      111       52   0.00170885  0.00149895\n",
       "11003     movies       91       51   0.00140095  0.00147012\n",
       "6389       first      101       51    0.0015549  0.00147012"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "misi = probabilities_df.loc[(probabilities_df.pred != y_test.reset_index(drop = True))].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fp</th>\n",
       "      <th>rp</th>\n",
       "      <th>indices</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11323</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1314</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9074</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2479</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9183</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fp   rp  indices    pred\n",
       "4   0.0  0.0    11323  rotten\n",
       "5   0.0  0.0     1314  rotten\n",
       "6   0.0  0.0     9074  rotten\n",
       "8   0.0  0.0     2479  rotten\n",
       "11  0.0  0.0     9183  rotten"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#access first 5 quotes in validation classifiers. they all ended up being misclassified anyway\n",
    "misclas = train.loc[misi.indices, :].quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The funniest, most knowing and, at heart, sweetest movie about making movies since Tim Burton's larky classic, Ed Wood.\n",
      "This movie gets its charge not from action pyrotechnics but from its electric barrage of language, wisecracks and dialogue, from the mordant '70s classicism of its long-take camera style and its smart, offbeat, strangely sexy cast.\n",
      "Cusack and Skye's relationship develops nicely and believably, but Crowe has not written an entirely convincing character for the latter to play.\n",
      "The mystery of Fischer's talent and torment adds depth to Searching for Bobby Fischer, about a young New York chess prodigy who doesn't want his genius to ruin his life.\n",
      "To watch the film -- directed with eye-opening vigor by Shekhar Kapur -- is to vicariously experience the social horrors of India's patriarchal system.\n"
     ]
    }
   ],
   "source": [
    "for quote in misclas:\n",
    "    print(quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['film', 'movie', 'one', 'like', 'good', 'story', 'much', 'comedy', 'time', 'director', 'best', 'even', 'little', 'funny', 'may', 'something', 'made', 'picture', 'movies', 'first']\n"
     ]
    }
   ],
   "source": [
    "print(list(table_r.word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['film', 'movie', 'one', 'like', 'good', 'story', 'even', 'time', 'comedy', 'much', 'director', 'best', 'characters', 'well', 'picture', 'action', 'first', 'may', 'made', 'funny']\n"
     ]
    }
   ],
   "source": [
    "print(list(table_f.word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*interpretation*\n",
    "\n",
    "It's difficult to tell which words would \"best\" predict a fresh or rotten model. As can see above, even with common english stop words removed, fresh and rotten words both have common 'movie' terms such as 'film'and 'movie'. However, we can see that the word 'much' is a better 'fresh' word than it is a 'rotten' word and the word 'even' is a better rotten word than it is a fresh word, even though both words are very common in both fresh and rotten.\n",
    "\n",
    "The quotes listed above are all rotten predicted but actually fresh. I think these quotes were easily misclassified because they contained a lot of movie terms, and these quotes criticized the movie, actors and directing more which would mean using common movie words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 NB with smoothing\n",
    "So, now you have your brand-new NB algorithm up and running. As a next step, we add smoothing to\n",
    "it. As you will be doing cross-validation below, your first task is to mold what you did above into two\n",
    "funcions: one for fitting and another one for predicting.\n",
    "1. Create two functions: one for fitting NB model, and another to predict outcome based on the fitted\n",
    "model.\n",
    "As mentioned above, the model is fully described with 4 probabilities, so your fitting function may\n",
    "return such a list as the model; and the prediction function may take it as an input.\n",
    "2. Add smoothing to the model. See Schutt p 103 and 109. Smoothing amounts to assuming that we\n",
    "have \u0010seen\u0011 every possible work Î± > 0 times already, for both classes. (If you wish, you can also\n",
    "assume you have seen the words Î± times for F and Î² times for R). Note that Î± does not have to be\n",
    "an integer, and typically the best Î± < 1.\n",
    "3. Now fit a few models with different Î±-s and see if the accuracy improves compared to the baseline\n",
    "case above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for fitting\n",
    "#parameters: X: prepared bag of words, y - classification, words- words in bag of words\n",
    "#returns dataframe of probabilities for each word in rotten/fresh text, and the priori probabilties for\n",
    "#fresh and rotten \n",
    "def fit(X, y, words,alpha):\n",
    "    #creates table that will be returned\n",
    "    result = {'f_count': [],'r_count': [], 'f_prob': [], 'r_prob' : []}\n",
    "    #computes priori probability \n",
    "    fpriori = len(y[y == 'fresh'])/len(y)\n",
    "    rpriori = len(y[y == 'rotten'])/len(y)\n",
    "    #organize BOW and classification into dataframe\n",
    "    X_df = pd.DataFrame(data = X, columns = words)\n",
    "    X_df['_val'] = y\n",
    "    #create calculate counts for fresh/rotten each word\n",
    "    rsum = X_df.loc[X_df['_val'] == 'rotten'].sum(axis = 0)[:-1]\n",
    "    fsum = X_df.loc[X_df['_val'] == 'fresh'].sum(axis = 0)[:-1]\n",
    "    result['r_count'] = rsum\n",
    "    result['f_count'] = fsum\n",
    "    result['r_prob'] = smoothprob(alpha, rsum)\n",
    "    result['f_prob'] = smoothprob(alpha, fsum) \n",
    "    #convert to dataframe\n",
    "    result = pd.DataFrame(data = result)\n",
    "    result = result.reset_index()\n",
    "    result.columns = ['words', 'f_count', 'r_count', 'f_prob', 'r_prob']\n",
    "    return result, fpriori, rpriori\n",
    "    \n",
    "#function for predicting\n",
    "def predict(table, f, r, Xt):\n",
    "    predictions = {'fp': [], 'rp': []}\n",
    "    for row in Xt:\n",
    "        fp, rp = findProb(row, table)\n",
    "        freshp = 0\n",
    "        rottenp = 0\n",
    "        freshp = np.prod(fp) * f\n",
    "        rottenp = np.prod(rp) * r\n",
    "        predictions['fp'].append(freshp)\n",
    "        predictions['rp'].append(rottenp)\n",
    "    predictions = pd.DataFrame(data = predictions)\n",
    "    predictions['pred'] = predictions['fp'] > predictions['rp']\n",
    "    predictions['pred'] = predictions['pred'].replace([True, False], ['fresh', 'rotten'])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function made for smoothing\n",
    "def smoothprob(alpha, sums):\n",
    "    newsums =  [(x + alpha) for x in sums]\n",
    "    newsums = [x/(alpha * len(sums) + sum(sums)) for x in newsums]\n",
    "    return newsums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add smoothing alpha = 1\n",
    "nb_fit, f, r = fit(X_train, y_train, words, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>f_count</th>\n",
       "      <th>r_count</th>\n",
       "      <th>f_prob</th>\n",
       "      <th>r_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>007</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>044</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  words f_count r_count    f_prob    r_prob\n",
       "0   000       3       0  0.000046  0.000003\n",
       "1  0014       0       0  0.000001  0.000003\n",
       "2   007       3       2  0.000046  0.000057\n",
       "3   044       0       1  0.000001  0.000030\n",
       "4    07       0       0  0.000001  0.000003"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_fit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict1 = predict(nb_fit, f, r, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fp</th>\n",
       "      <th>rp</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>7.142673e-11</td>\n",
       "      <td>3.576093e-09</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>3.183950e-69</td>\n",
       "      <td>2.547799e-68</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>8.676050e-40</td>\n",
       "      <td>7.042108e-39</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>1.279738e-40</td>\n",
       "      <td>1.813403e-39</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>4.279123e-132</td>\n",
       "      <td>1.186490e-133</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>7.204958e-61</td>\n",
       "      <td>1.459291e-62</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>9.466908e-41</td>\n",
       "      <td>6.713255e-41</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>5.150933e-78</td>\n",
       "      <td>1.018562e-75</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>8.388483e-80</td>\n",
       "      <td>2.901441e-79</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>2.889668e-56</td>\n",
       "      <td>8.316961e-56</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 fp             rp    pred\n",
       "1171   7.142673e-11   3.576093e-09  rotten\n",
       "126    3.183950e-69   2.547799e-68  rotten\n",
       "163    8.676050e-40   7.042108e-39  rotten\n",
       "590    1.279738e-40   1.813403e-39  rotten\n",
       "1051  4.279123e-132  1.186490e-133   fresh\n",
       "1404   7.204958e-61   1.459291e-62   fresh\n",
       "395    9.466908e-41   6.713255e-41   fresh\n",
       "1820   5.150933e-78   1.018562e-75  rotten\n",
       "580    8.388483e-80   2.901441e-79  rotten\n",
       "1007   2.889668e-56   8.316961e-56  rotten"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict1.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[858, 474],\n",
       "       [540, 275]], dtype=int64)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, predict1.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.527713088029809"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predict1.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_fit, f, r = fit(X_train, y_train, words, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>f_count</th>\n",
       "      <th>r_count</th>\n",
       "      <th>f_prob</th>\n",
       "      <th>r_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>astringency</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16398</th>\n",
       "      <td>suddenly</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16608</th>\n",
       "      <td>sweepstakes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6034</th>\n",
       "      <td>factor</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11234</th>\n",
       "      <td>negligent</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9883</th>\n",
       "      <td>locomotive</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7431</th>\n",
       "      <td>grisham</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5276</th>\n",
       "      <td>eco</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12630</th>\n",
       "      <td>poor</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8302</th>\n",
       "      <td>ideologically</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               words f_count r_count    f_prob    r_prob\n",
       "1144     astringency       0       1  0.000007  0.000034\n",
       "16398       suddenly       2       1  0.000034  0.000034\n",
       "16608    sweepstakes       0       0  0.000007  0.000011\n",
       "6034          factor       5       0  0.000074  0.000011\n",
       "11234      negligent       0       1  0.000007  0.000034\n",
       "9883      locomotive       1       1  0.000020  0.000034\n",
       "7431         grisham       5       0  0.000074  0.000011\n",
       "5276             eco       0       0  0.000007  0.000011\n",
       "12630           poor       7       3  0.000101  0.000079\n",
       "8302   ideologically       1       0  0.000020  0.000011"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_fit.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict2 = predict(nb_fit, f, r, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[954, 378],\n",
       "       [610, 205]], dtype=int64)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, predict2.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5398230088495575"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predict2.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1046  286]\n",
      " [ 648  167]]\n",
      "0.5649743828598044\n"
     ]
    }
   ],
   "source": [
    "nb_fit, f, r = fit(X_train, y_train, words, 0.75)\n",
    "predict3 = predict( nb_fit, f, r, X_test)\n",
    "print(confusion_matrix(y_test, predict3.pred))\n",
    "print(accuracy_score(y_test, predict3.pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1134  198]\n",
      " [ 698  117]]\n",
      "0.5826734979040522\n"
     ]
    }
   ],
   "source": [
    "nb_fit, f, r = fit(X_train, y_train, words, 0.99)\n",
    "predict4 = predict( nb_fit, f, r, X_test)\n",
    "print(confusion_matrix(y_test, predict4.pred))\n",
    "print(accuracy_score(y_test, predict4.pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1291   41]\n",
      " [ 773   42]]\n",
      "0.6208663251047974\n"
     ]
    }
   ],
   "source": [
    "nb_fit, f, r = fit(X_train, y_train, words, 2)\n",
    "predict5 = predict( nb_fit, f, r, X_test)\n",
    "print(confusion_matrix(y_test, predict5.pred))\n",
    "print(accuracy_score(y_test, predict5.pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Cross-Validation\n",
    "Finally (well, almost finally), we do cross-validation. This is another piece of code you have to implement\n",
    "yourself, not use existing libraries.\n",
    "\n",
    "* Implement k-fold CV. I recommend to implement it as a function that a) puts your data into\n",
    "random order; b) splits these into k chunks; c) selects a chunk for testing and the others for training;d) trains your NB model on the training chunks; e) computes accuracy on training chunk; f) returns mean accuracy over all these k trials. The function should also take Î± as an argument, this is the hyperparameter you are going to optimize.\n",
    "\n",
    "* Find the optimal Î± by 5-fold CV using your own CV code. You have to find the cross-validated\n",
    "accuracies for a number of Î±-s between 0 and 1. Present the accuracy as a function of Î± on a plot\n",
    "and indicate which one is the best Î±."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-fold cv function\n",
    "def crossval(alpha, data, words, K):\n",
    "    #makes copy of data and splits into K chunks\n",
    "    data_copy = data.sample(frac=1).reset_index(drop = True)\n",
    "    n = int(len(data_copy)/K)\n",
    "    list_chunks = [data_copy[i:i+n] for i in range(0,data_copy.shape[0],n)]\n",
    "    accuracies = []\n",
    "    for i in range(K):\n",
    "        test_ch = list_chunks.pop(i)\n",
    "        tX = test_ch.drop('_val', axis = 1)\n",
    "        tX = tX.as_matrix()\n",
    "        ty = test_ch['_val']\n",
    "        chunk = pd.concat(list_chunks)\n",
    "        X = chunk.drop(['_val'], axis = 1)\n",
    "        X = X.as_matrix()\n",
    "        y = chunk['_val']\n",
    "        fitted,f,r = fit(X, y, words, alpha)\n",
    "        predicted = predict(fitted, f, r, tX)\n",
    "        accuracies.append(accuracy_score(ty, predicted.pred))\n",
    "        list_chunks.insert(i, test_ch) \n",
    "    acc = np.mean(accuracies)\n",
    "    return acc, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(data = X, columns = words)\n",
    "X_df['_val'] = train.fresh.reset_index()['fresh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "#1 out of 5 folds alpha = 0.2\n",
    "a,b = crossval(0.2, X_df, words, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "#2 out of 5 folds alpha = 0.4\n",
    "c,d = crossval(0.4, X_df, words, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "#3 out of 5 folds alpha = 0.6\n",
    "e,f = crossval(0.6, X_df, words, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "#4 out of 5 folds alpha = 0.8\n",
    "g,h = crossval(0.8, X_df, words, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "#5 out of 5 folds alpha = 0.0\n",
    "i, j = crossval(0, X_df, words, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5171867722403353 0.6791802515137401 0.6884955752212389 0.6935258500232883 0.6991150442477877\n"
     ]
    }
   ],
   "source": [
    "print(i,a, c, e, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x17db99aa710>]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xt0XeV55/Hvo/vFliVZsrEty3JA5g4mCAN2kgINxElTIA2lNgPYkIRJJjRrJh0WMO1qu8jKNJ1Zq0zb8eoskiIbAhhwSzAtxA0NJKlsg2UwF5sYhCXbso0tS/JN98szf5wtc3R8bB1Zl32k8/usdZb2fve793n2MbzPu9/9nrPN3REREUkLOwAREUkOSggiIgIoIYiISEAJQUREACUEEREJKCGIiAighCAiIgElBBERAZQQREQkkBF2AMNRUlLiFRUVYYchIjKhbN269bC7lw5Vb0IlhIqKCmpra8MOQ0RkQjGz3YnU05CRiIgASggiIhJQQhAREUAJQUREAgklBDNbamY7zazOzB6Ks/1RM9sWvD40syNR21aY2UfBa0VU+ZVm9l5wzL8zMxudUxIRkbMx5CwjM0sHVgE3Ao3AFjNb7+47Buq4+3+Lqv/HwBXBcjHwF0AV4MDWYN9W4B+A+4DNwMvAUuCVUTovEREZpkSuEBYBde6+y927gbXALWeovxx4Jlj+EvALd28JksAvgKVmNgsocPdNHnlk2xPArWd9FiIiMmKJfA9hDrA3ar0RuDpeRTObB8wHfnmGfecEr8Y45fGOeR+RKwnKy8sTCFdEZGLq6O6jpb2blhPdkb9tXbS09dDS1sV9nz+XaXmZY/r+iSSEeGP7p3sQ8zJgnbv3DbFvwsd098eAxwCqqqr0AGgRmRD6+p0j7d20tnfTfCL429ZNa1v3yUa+pT3yt7Wth+a2Ljp7+uMeKz3NuGXhnKRICI3A3Kj1MmD/aeouA74bs+91Mfu+HpSXJXhMEZFQuTsdPX0nG/aWtsGveI3+kY4e/DRd2KnZGRTlZ1GUn8WMqTmcP7OA6VOyKMrLYnpQXpyfSXF+NsV5WRTkZjAe824SSQhbgEozmw/sI9Lo3xFbyczOB4qATVHFG4D/aWZFwfpNwMPu3mJmx83sGuAN4G7g78/+NEREEtfb18+Rjh5a2z5twAf9jWr0B8q6euP33jPSjKL8oCHPy+LCWQUU52VRnB95RW+bPiWLwrxMsjPSx/mMEzNkQnD3XjO7n0jjng487u7bzewRoNbd1wdVlwNrg5vEA/u2mNkPiCQVgEfcvSVY/g6wGsglMrtIM4xEZNjcnfbuvlN67S1tkXH46MZ+oOzomXrvORknG/NzCnK4cFZBVK89K9LYT4n8LcrPoiBnfHrv48H8dJ9KEqqqqnL9uJ3I5Nbb109re8/g4ZjoBj1Oo999mt57ZrpFeulRPfZTXnmf9uIL87LIyph839c1s63uXjVUvQn1a6ciMrF09/ZztKOHI+2RMfUj7T20tndzpD3qxmpbz6AhmqMdPac9XkFU7312YQ6XzCkYNCQT29hPyZ48vffxoIQgIkPq6Rto2IPGvb0naOC7P23kO3o4erLB7+FoRw8nunpPe8ys9LRBY+yXzJkW1bBHbqgW5WcyPfhblJdFZvrk670nEyUEkRTSO9CwD9G4H43qzR9t7+H4GRr29DSjMDeTaXmRRvucghwuOKeAwrxMCnMzKczPojA3sq0wL5NpuZkU5mWq956ElBBEJqC+fudYR/yeeezwTHTjfrzz9A17mkFhXtbJxr10ajaVM6ZEyvIyg1dke2HQ+E/Ly2SqGvZJQwlBJET9/c6xzp7TDrtEN+7Ry8c6Tz9LxoxILzw30oAX52dxbumUkz3zopMN/KeNe2FeFlOzM0hLU8OeypQQREZBf79zvLOXIx3xh11O17ifafojcLIRH2jcK0ryIz3zmF569JBMQU6mGnY5K0oIIglwd1rautnT0s6elnb2Bn8jyx0cONpB/xka9qk5GYPG0MuL8wY19PEa94LcTNLVsMs4UkIQCXT19tHY2vFpg9/cPigBtHX3Dao/Y2o25cV5XD2/mNmFuacOxwSN+7TcTDI0O0YmACUESRnuTnPQy9/b0s7umAb/k2Odg4ZvcjLTKC/Oo7w4j2vPnX5yubw4j7KiPHKzkvPnB0TOlhKCTCqdPZFefvSQTvQQT3tML39mQfbJBn9ecT7l03MpL85jbnEepVOyNXtGUooSgkwo7k7Tia5PG/zmjkEN/ifHOgfVz81MP9nALz63hPLiXMqnf9rLz8lUL19kgBKCJJ1IL3+gwW9nT8vgRr+jZ3Avf9a0HOYW5/G5ypKTQzpzg78lU7LUyxdJkBKCjDt3p+l416AhnegG/+CxrkH187Iivfzy6ac2+mVFuerli4wSJQQZEx3dUb38lujefjt7W9sHPRnKDGYVRHr5X6gsPdn4D/Typ+erly8yHpQQ5Kz090fG8gc19FGN/6Hjg3v5+VnpzC3OY35JPtedXzpoWGdOUW7SPjBEJJUoIchpdXT3xR3SGViOfoKUGcyelsvc4txTGvzy4jyK1csXSXpKCHKKdVsb+euf/5ammF7+lOwMyovzOK90CjdcMGNQgz+7MEe9fJEJTglBBuns6eOvXv6AGQU5rFxccbLRnxf81IJ6+SKTV0IJwcyWAn9L5JnKP3H3H8Wpczvwl4AD77j7HWZ2PfBoVLULgGXu/jMzWw38DnA02LbS3bed7YnI6Hjpnf00t3Xz98uvYPF5JWGHIyLjaMiEYGbpwCrgRqAR2GJm6919R1SdSuBhYIm7t5rZDAB3fw1YGNQpBuqAf4s6/APuvm60TkZGxt2prmng/JlTufbc6WGHIyLjLJFf3FoE1Ln7LnfvBtYCt8TU+Rawyt1bAdz9UJzj3Aa84u7tIwlYxs6b9S3sOHCMlUsqNDQkkoISSQhzgL1R641BWbQFwAIzqzGzzcEQU6xlwDMxZT80s3fN7FEzy4735mZ2n5nVmlltU1NTAuHK2Vq9sYHCvExuXRj7zysiqSCRhBCvqxj7y+8ZQCVwHbAc+ImZFZ48gNks4FJgQ9Q+DxO5p3AVUAw8GO/N3f0xd69y96rS0tIEwpWz0djazobtn7B8Ubl+xVMkRSWSEBqBuVHrZcD+OHVedPced68HdhJJEANuB15w956BAnc/4BFdQDWRoSkJyZObdmNm3HXNvLBDEZGQJJIQtgCVZjbfzLKIDP2sj6nzM+B6ADMrITKEtCtq+3JihouCqwYsMlh9K/D+2ZyAjFx7dy/PvLmHpRefw+zC3LDDEZGQDDnLyN17zex+IsM96cDj7r7dzB4Bat19fbDtJjPbAfQRmT3UDGBmFUSuMH4Vc+inzKyUyJDUNuDbo3NKMlwvvL2PY5293LOkIuxQRCRE5md6wneSqaqq8tra2rDDmFTcnZse/TXZmWm8dP/nNLtIZBIys63uXjVUPT3oNcXV1DXz0aET3LN4vpKBSIpTQkhx1TX1lEzJ4quXzwo7FBEJmRJCCms43MYvdx7ijqvn6YfpREQJIZWt2dRARppx5zXlYYciIklACSFFHe/s4fnaRr562WxmTM0JOxwRSQJKCClq3dZGTnT1snJxRdihiEiSUEJIQf39zpqNDXy2vJDL5xYOvYOIpAQlhBT0+oeHaGhu554l88MORUSSiBJCCqquaeCcghyWXnJO2KGISBJRQkgxHx08zm8+Osxd184jM13//CLyKbUIKWb1xgayMtJYvkhTTUVkMCWEFHK0vYd/fmsfty6cTXF+VtjhiEiSUUJIIc/W7qGjp083k0UkLiWEFNHb18+ajbu55jPFXDirIOxwRCQJKSGkiFc/OMi+Ix2sXKyrAxGJTwkhRVTXNFBWlMuNF80MOxQRSVJKCClg+/6jvFHfwoprK0hP0zMPRCQ+JYQUsLqmgdzMdG6vmht2KCKSxBJKCGa21Mx2mlmdmT10mjq3m9kOM9tuZk9HlfeZ2bbgtT6qfL6ZvWFmH5nZs2ameZBjoPlEFy++s5+vXzmHaXmZYYcjIklsyIRgZunAKuDLwEXAcjO7KKZOJfAwsMTdLwb+a9TmDndfGLxujir/a+BRd68EWoFvjOxUJJ5n3txDd2+/ftVURIaUyBXCIqDO3Xe5ezewFrglps63gFXu3grg7ofOdECLPLz3BmBdULQGuHU4gcvQevr6eXLzbj5fWcJ5M6aGHY6IJLlEEsIcYG/UemNQFm0BsMDMasxss5ktjdqWY2a1QflAoz8dOOLuvWc4pozQK+9/wsFjXdyrL6KJSAIyEqgTb1qKxzlOJXAdUAb8xswucfcjQLm77zezzwC/NLP3gGMJHDPy5mb3AfcBlJfr93eGo7qmnvkl+fzOgtKwQxGRCSCRK4RGIHp6ShmwP06dF929x93rgZ1EEgTuvj/4uwt4HbgCOAwUmlnGGY5JsN9j7l7l7lWlpWrYErVt7xHe3nOEFdfOI01TTUUkAYkkhC1AZTArKAtYBqyPqfMz4HoAMyshMoS0y8yKzCw7qnwJsMPdHXgNuC3YfwXw4khPRj61uqaeqdkZ3KappiKSoCETQjDOfz+wAfgAeM7dt5vZI2Y2MGtoA9BsZjuINPQPuHszcCFQa2bvBOU/cvcdwT4PAt83szoi9xT+cTRPLJUdOtbJv753gD+smsuU7ERGBUVEEruHgLu/DLwcU/bnUcsOfD94RdfZCFx6mmPuIjKDSUbZTzfvprffWbF4XtihiMgEom8qTzJdvX089cYefveCGcybnh92OCIygSghTDIvvXOA5rZuPfNARIZNCWEScXeqa+pZMHMKi8+dHnY4IjLBKCFMIrW7W9m+/xgrF88n8mVwEZHEKSFMItU19UzLzeRrV+hL3yIyfEoIk8S+Ix1s2H6QZYvmkpuVHnY4IjIBKSFMEk9u2g3A3ddWhBuIiExYSgiTQEd3H8+8uYcvXTyTOYW5YYcjIhOUEsIk8MLb+zja0cPKxZpqKiJnTwlhgnN3Vm+s5+LZBVxVURR2OCIygSkhTHAbP27mw4MnuGeJppqKyMgoIUxw1TX1TM/P4quXzQo7FBGZ4JQQJrDdzW38+28P8Z+uLicnU1NNRWRklBAmsDUbd5Nuxp3X6FdNRWTklBAmqBNdvTxfu5ffu2wWMwpywg5HRCYBJYQJ6p+2NnK8q1e/aioio0YJYQLq73dWb2zgivJCFs4tDDscEZkklBAmoF992ET94TZWLq4IOxQRmUQSSghmttTMdppZnZk9dJo6t5vZDjPbbmZPB2ULzWxTUPaumf1RVP3VZlZvZtuC18LROaXJr3pjAzMLsvnKpZpqKiKjZ8hnKptZOrAKuBFoBLaY2Xp33xFVpxJ4GFji7q1mNiPY1A7c7e4fmdlsYKuZbXD3I8H2B9x93Wie0GRXd+gEv/6wif9+0wIy03WBJyKjJ5EWZRFQ5+673L0bWAvcElPnW8Aqd28FcPdDwd8P3f2jYHk/cAgoHa3gU9HqjfVkZaSxfFF52KGIyCSTSEKYA+yNWm8MyqItABaYWY2ZbTazpbEHMbNFQBbwcVTxD4OhpEfNLHuYsaecox09/NPWfdxy+WymT9HHJSKjK5GEEO8HcjxmPQOoBK4DlgM/MbOT01/MbBbwJHCPu/cHxQ8DFwBXAcXAg3Hf3Ow+M6s1s9qmpqYEwp28ntuyl46ePlYuqQg7FBGZhBJJCI3A3Kj1MmB/nDovunuPu9cDO4kkCMysAPhX4M/cffPADu5+wCO6gGoiQ1OncPfH3L3K3atKS1N3tKmv31mzqYFF84u5ePa0sMMRkUkokYSwBag0s/lmlgUsA9bH1PkZcD2AmZUQGULaFdR/AXjC3Z+P3iG4asAiP9F5K/D+SE5ksnv1g4M0tnZwr64ORGSMDDnLyN17zex+YAOQDjzu7tvN7BGg1t3XB9tuMrMdQB+R2UPNZnYn8AVgupmtDA650t23AU+ZWSmRIaltwLdH++Qmk+qaeuYU5vLFC2eGHYqITFLmHns7IHlVVVV5bW1t2GGMuw8OHOPLf/sbHv7yBfzn3zk37HBEZIIxs63uXjVUPU1knwBW1zSQm5nOsqs01VRExo4SQpJraevmZ9v28QefncO0vMywwxGRSUwJIck98+Yeunr79btFIjLmlBCSWE9fP09u2s3nK0uonDk17HBEZJJTQkhiP3//Ez451sk9mmoqIuNACSGJVdfUUzE9j+sWzBi6sojICCkhJKl39h7hrT1HWLG4grS0eL8eIiIyupQQktTqjQ1Myc7gtivLwg5FRFKEEkISOnSsk395dz+3XVnG1BxNNRWR8aGEkISeemMPvf2uqaYiMq6UEJJMV28fT72xmxvOn0FFSX7Y4YhIClFCSDL/8s4BDp/o1jMPRGTcKSEkEXdn9cYGKmdM4XPnlYQdjoikGCWEJLJ1dyvv7TvKyiUVRB4TISIyfpQQkkh1TQMFORl87YrYR1aLiIw9JYQksf9IBz/f/gnLF5WTlzXkc4tEREadEkKSeHLzbtydu66dF3YoIpKilBCSQEd3H8+8uYebLjqHsqK8sMMRkRSVUEIws6VmttPM6szsodPUud3MdpjZdjN7Oqp8hZl9FLxWRJVfaWbvBcf8O0vhu6gvbtvHkfYe/aqpiIRqyMFqM0sHVgE3Ao3AFjNb7+47oupUAg8DS9y91cxmBOXFwF8AVYADW4N9W4F/AO4DNgMvA0uBV0bz5CYCd6e6poGLZhWwaH5x2OGISApL5AphEVDn7rvcvRtYC9wSU+dbwKqgocfdDwXlXwJ+4e4twbZfAEvNbBZQ4O6b3N2BJ4BbR+F8JpxNHzez8+BxTTUVkdAlkhDmAHuj1huDsmgLgAVmVmNmm81s6RD7zgmWz3TMlFC9sYHp+VncfPnssEMRkRSXyPzGeN1Wj3OcSuA6oAz4jZldcoZ9Ezlm5M3N7iMytER5eXkC4U4ce5rbefWDg9x//XnkZKaHHY6IpLhErhAagblR62XA/jh1XnT3HnevB3YSSRCn27cxWD7TMQFw98fcvcrdq0pLSxMId+JYs6mBdDPuvEZTTUUkfIkkhC1ApZnNN7MsYBmwPqbOz4DrAcyshMgQ0i5gA3CTmRWZWRFwE7DB3Q8Ax83smmB20d3Ai6NyRhNEW1cvz23Zy1cuncXMgpywwxERGXrIyN17zex+Io17OvC4u283s0eAWndfz6cN/w6gD3jA3ZsBzOwHRJIKwCPu3hIsfwdYDeQSmV2UUjOM/umtRo539WqqqYgkDYtM8pkYqqqqvLa2NuwwRqy/3/ni3/yKqbmZvPjdJWGHIyKTnJltdfeqoerpm8oh+PVHTew63Ma9ujoQkSSihBCC6poGZkzN5suXzAo7FBGRk5QQxlndoRP86sMm7rxmHlkZ+vhFJHmoRRpnT2xqICs9jTuunlzfqRCRiU8JYRwd7ehh3dZGbl44m5Ip2WGHIyIyiBLCOHq+di/t3X2sXFwRdigiIqdQQhgnff3Omk0NLKoo5pI508IOR0TkFEoI4+TfPzjI3pYOfRFNRJKWEsI4qa5pYE5hLjdeNDPsUERE4lJCGAe//eQYm3Y1c9e188hI10cuIslJrdM4WF3TQE5mGsuumjt0ZRGRkCghjLGWtm5eeHsfX7uijMK8rLDDERE5LSWEMbZ2yx66evt1M1lEkp4Swhjq6evnyU27+dx5JSyYOTXscEREzkgJYQxt2P4JB4526otoIjIhKCGModU1DcybnscNF8wIOxQRkSEpIYyR9xqPUru7lRXXVpCWZmGHIyIyJCWEMVJdU09+Vjq3VZWFHYqISEISSghmttTMdppZnZk9FGf7SjNrMrNtweubQfn1UWXbzKzTzG4Ntq02s/qobQtH99TCc+h4Jy+9u58/rJpLQU5m2OGIiCQkY6gKZpYOrAJuBBqBLWa23t13xFR91t3vjy5w99eAhcFxioE64N+iqjzg7utGEH9SevqNPfT0OSt0M1lEJpBErhAWAXXuvsvdu4G1wC1n8V63Aa+4e/tZ7DthdPX28dPNe7j+/FLml+SHHY6ISMISSQhzgL1R641BWayvm9m7ZrbOzOL9RsMy4JmYsh8G+zxqZpPiiTEvv3eAwye6uGfJ/LBDEREZlkQSQrwpMh6z/hJQ4e6XAa8CawYdwGwWcCmwIar4YeAC4CqgGHgw7pub3WdmtWZW29TUlEC44XF3qmsaOG/GFD5fWRJ2OCIiw5JIQmgEonv8ZcD+6Aru3uzuXcHqj4ErY45xO/CCu/dE7XPAI7qAaiJDU6dw98fcvcrdq0pLSxMINzxv7Wnl3cajrFhcgZmmmorIxJJIQtgCVJrZfDPLIjL0sz66QnAFMOBm4IOYYywnZrhoYB+LtJy3Au8PL/TkU13TQEFOBl//bLwRNRGR5DbkLCN37zWz+4kM96QDj7v7djN7BKh19/XA98zsZqAXaAFWDuxvZhVErjB+FXPop8yslMiQ1Dbg2yM+mxAdONrBK+9/wjc+N5+8rCE/VhGRpJNQy+XuLwMvx5T9edTyw0TuCcTbt4E4N6Hd/YbhBJrsnty0G3fnrmvmhR2KiMhZ0TeVR0FnTx/PvLmHGy+aydzivLDDERE5K0oIo+DFbftobe/RVFMRmdCUEEZoYKrpBedM5er5xWGHIyJy1pQQRmjzrhZ++8lx7l0yX1NNRWRCU0IYoeqaeorzs7h54eywQxERGRElhBHY29LOLz44yPJFc8nJTA87HBGREVFCGIEnNjWQbsZd11SEHYqIyIgpIZyltq5e1m7Zy5cvncU503LCDkdEZMSUEM7SP7/VyPHOXlbqmQciMkkoIZyF/n5n9cYGLi+bxmfLC8MOR0RkVCghnIXf1B3m46Y27tFUUxGZRJQQzkJ1TT2lU7P5yqWzhq4sIjJBKCEM066mE7y+s4k7r55HVoY+PhGZPNSiDdOajQ1kpadxx9XlYYciIjKqlBCG4VhnD+u2NvLVy2dROnVSPAJaROQkJYRheL62kbbuPu7Vr5qKyCSkhJCgvn5nzcYGrqoo4pI508IOR0Rk1CkhJOiXvz3EnpZ2Vi7W1YGITE5KCAlavbGe2dNy+NLFM8MORURkTCSUEMxsqZntNLM6M3sozvaVZtZkZtuC1zejtvVFla+PKp9vZm+Y2Udm9qyZZY3OKY2+nZ8cp6aumbuurSAjXTlURCanIVs3M0sHVgFfBi4ClpvZRXGqPuvuC4PXT6LKO6LKb44q/2vgUXevBFqBb5z9aYyt1RvryclMY9lVc8MORURkzCTS3V0E1Ln7LnfvBtYCt4zkTS3yew83AOuCojXArSM55lhpbevmhbf38bUr5lCUn7QXMSIiI5ZIQpgD7I1abwzKYn3dzN41s3VmFt2VzjGzWjPbbGYDjf504Ii79w5xTMzsvmD/2qampgTCHV1rt+yls6dfN5NFZNJLJCHE+/U2j1l/Cahw98uAV4n0+AeUu3sVcAfwf8zs3ASPGSl0f8zdq9y9qrS0NIFwR09vXz9Pbmpg8bnTOf+cqeP63iIi4y2RhNAIRPf4y4D90RXcvdndu4LVHwNXRm3bH/zdBbwOXAEcBgrNLON0x0wG/7bjIPuPdnKPvogmIikgkYSwBagMZgVlAcuA9dEVzCz6Zz9vBj4IyovMLDtYLgGWADvc3YHXgNuCfVYAL47kRMZCdU095cV53HDBjLBDEREZc0MmhGCc/35gA5GG/jl3325mj5jZwKyh75nZdjN7B/gesDIovxCoDcpfA37k7juCbQ8C3zezOiL3FP5xtE5qNLy/7yhbGlq5+9p5pKfpmQciMvlZpLM+MVRVVXltbe24vNefPPcOP3//AJv+x+9SkJM5Lu8pIjIWzGxrcC/3jPQtqziajnfx0jv7ue3KMiUDEUkZSghxPP3GHrr7+rl7cUXYoYiIjBslhBjdvf389I3dXHd+KeeWTgk7HBGRcaOEEOPl9w7QdLxLU01FJOUoIURxd6pr6vlMaT6fP68k7HBERMaVEkKUt/ce4Z3Go9yzuII0TTUVkRSjhBCluqaBqTkZ/MFny8IORURk3CkhBD452skr7x3gj6rmkp+dMfQOIiKTjBJC4Kebd9PvzgpNNRWRFKWEAHT29PH0m3v44oUzmVucF3Y4IiKhUEIA1m/bT0tbNyuXVIQdiohIaFI+Ibg71RsbuOCcqVz7melhhyMiEpqUTwhv1LfwwYFj3LOkgsiTPUVEUlPKJ4TqmnqK8jK5ZWHcJ3iKiKSMlE4Ie1va+cWOgyxfVE5OZnrY4YiIhCqlE8KTm3djZtx17bywQxERCV3KJoT27l7WvrmHpZecw6xpuWGHIyISupRNCP/81j6OdfZyr6aaiogACSYEM1tqZjvNrM7MHoqzfaWZNZnZtuD1zaB8oZltCp63/K6Z/VHUPqvNrD5qn4Wjd1pn5u6s3tjAZWXT+Gx50Xi9rYhIUhvyR3vMLB1YBdwINAJbzGy9u++Iqfqsu98fU9YO3O3uH5nZbGCrmW1w9yPB9gfcfd0Iz2HYfvPRYeoOneBvbr9cU01FRAKJXCEsAurcfZe7dwNrgVsSObi7f+juHwXL+4FDQOnZBjtaVm9soGRKNr932aywQxERSRqJJIQ5wN6o9cagLNbXg2GhdWY2N3ajmS0CsoCPo4p/GOzzqJllx3tzM7vPzGrNrLapqSmBcM+s/nAbv/ztIe68ppzsDE01FREZkEhCiDem4jHrLwEV7n4Z8CqwZtABzGYBTwL3uHt/UPwwcAFwFVAMPBjvzd39MXevcveq0tKRX1ys2dhAZrpxx9XlIz6WiMhkkkhCaASie/xlwP7oCu7e7O5dweqPgSsHtplZAfCvwJ+5++aofQ54RBdQTWRoakwd7+zh+dq9/P5ls5kxNWes305EZEJJJCFsASrNbL6ZZQHLgPXRFYIrgAE3Ax8E5VnAC8AT7v58vH0sclf3VuD9sz2JRD1f20hbdx/3LJk/1m8lIjLhDDnLyN17zex+YAOQDjzu7tvN7BGg1t3XA98zs5uBXqAFWBnsfjvwBWC6mQ2UrXT3bcBTZlZKZEhqG/Dt0TutU/X1O2s2NXDlvCIuLZs2lm8lIjIhJfSsSHcGFhCyAAAFFklEQVR/GXg5puzPo5YfJnJPIHa/nwI/Pc0xbxhWpCP0+s5D7G5u54EvnT+ebysiMmGkzDeVq2samDUthy9dfE7YoYiIJKWUSAgfHjzOf9Qd5s5r5pGZnhKnLCIybCnROq7e2EB2Rhp3LNJUUxGR00mJhDC3KI97PzefovyssEMREUlaCd1Unui+c925YYcgIpL0UuIKQUREhqaEICIigBKCiIgElBBERARQQhARkYASgoiIAEoIIiISUEIQEREAzD324WfJy8yagN1nuXsJcHgUwxktimt4FNfwKK7hmaxxzXP3IR85OaESwkiYWa27V4UdRyzFNTyKa3gU1/CkelwaMhIREUAJQUREAqmUEB4LO4DTUFzDo7iGR3ENT0rHlTL3EERE5MxS6QpBRETOYNIlBDNbamY7zazOzB6Ksz3bzJ4Ntr9hZhVJEtcXzOwtM+s1s9vGI6YE4/q+me0ws3fN7N/NbF6SxPVtM3vPzLaZ2X+Y2UXJEFdUvdvMzM1sXGasJPB5rTSzpuDz2mZm30yGuII6twf/jW03s6eTIS4zezTqs/rQzI4kSVzlZvaamb0d/D/5lVENwN0nzQtIBz4GPgNkAe8AF8XU+S/A/wuWlwHPJklcFcBlwBPAbUn0eV0P5AXL30miz6sgavlm4OfJEFdQbyrwa2AzUJUMcQErgf87Hv9dDTOuSuBtoChYn5EMccXU/2Pg8WSIi8i9hO8EyxcBDaMZw2S7QlgE1Ln7LnfvBtYCt8TUuQVYEyyvA37XzCzsuNy9wd3fBfrHOJbhxvWau7cHq5uBsiSJ61jUaj4wHjfDEvnvC+AHwP8COschpuHENd4SietbwCp3bwVw90NJEle05cAzSRKXAwXB8jRg/2gGMNkSwhxgb9R6Y1AWt4679wJHgelJEFcYhhvXN4BXxjSiiITiMrPvmtnHRBrf7yVDXGZ2BTDX3f9lHOJJOK7A14NhhnVmNjdJ4loALDCzGjPbbGZLkyQuAIIh0vnAL5Mkrr8E7jSzRuBlIlcvo2ayJYR4Pf3YnmMidUZbGO+ZiITjMrM7gSrgf49pRMHbxSk7JS53X+Xu5wIPAn825lENEZeZpQGPAn8yDrFES+TzegmocPfLgFf59Cp5LCUSVwaRYaPriPTEf2JmhUkQ14BlwDp37xvDeAYkEtdyYLW7lwFfAZ4M/rsbFZMtITQC0T2fMk69pDpZx8wyiFx2tSRBXGFIKC4z+yLwp8DN7t6VLHFFWQvcOqYRRQwV11TgEuB1M2sArgHWj8ON5SE/L3dvjvq3+zFw5RjHlFBcQZ0X3b3H3euBnUQSRNhxDVjG+AwXQWJxfQN4DsDdNwE5RH7naHSM9Y2S8XwR6W3sInKJN3BT5uKYOt9l8E3l55Ihrqi6qxm/m8qJfF5XELnRVZlk/46VUcu/D9QmQ1wx9V9nfG4qJ/J5zYpa/hqwOUniWgqsCZZLiAyZTA87rqDe+UADwfe1kuTzegVYGSxfSCRhjFp8Y36S4/0ichn1YdCI/WlQ9giR3i1EMurzQB3wJvCZJInrKiI9hDagGdieJHG9ChwEtgWv9UkS198C24OYXjtTwzyeccXUHZeEkODn9VfB5/VO8HldkCRxGfA3wA7gPWBZMsQVrP8l8KPxiGcYn9dFQE3w77gNuGk031/fVBYREWDy3UMQEZGzpIQgIiKAEoKIiASUEEREBFBCEBGRgBKCiIgASggiIhJQQhAREQD+Pxt3Y9snWKGbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(data = {'alpha': [0.0, 0.2, 0.4, 0.6, 0.8], 'acc': [i,a,c,e,g]})\n",
    "plt.plot(df.alpha, df.acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8 is the best alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Final model performance\n",
    "Finally (and now I mean finally,), estimate the model performance on the testing data. Complete this\n",
    "section after everything else is done and you are ready to submit your work. Don't improve model\n",
    "after you have loaded testing data!\n",
    "1. Fit your NB model using the cross-validated optimal alpha using your complete work data (both\n",
    "training and validation). This is your best and final model.\n",
    "2. Load your testing data. Clean it using exactly the same procedure (you made a function for this,\n",
    "right?) and transform it into BOW-s.\n",
    "Note: above I suggested using vectorizer.fit_transform(quote) function to create the BOW.\n",
    "Here I recommend to use vectorizer.transform(quote). This is because we don't want to change\n",
    "the vocabulary (that's what the fit-part does), only to transform it into the BOW.\n",
    "3. Predict the F/R class on testing data. Compute accuracy. Present it.\n",
    "4. Did you get a better or worse result compared to the k-NN and TF-IDF in PS04?\n",
    "That is it. This is your final model performance measure. Feel free to compare it with your peers, but\n",
    "even if abysmal, don't play with the model any more! Just submit, and you are done ,... really\n",
    "done, this was your last problem set!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare test data\n",
    "test = pd.read_csv(\"test_data.csv\", sep = '\\t')\n",
    "X_val = vectorizer.transform(test.quote.values).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit model with entire train \n",
    "model_fit, f, r = fit(X, train.fresh, words, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred = predict(model_fit, f, r, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1326,  354],\n",
       "       [ 799,  205]], dtype=int64)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test.fresh, model_pred.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5704172876304023"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test.fresh, model_pred.pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the Naive Bayes was better than my Knn or Tfidf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
